{
  "best_metric": 2.2166941165924072,
  "best_model_checkpoint": "./results\\checkpoint-486",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 486,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0411522633744856,
      "grad_norm": 3.8521265983581543,
      "learning_rate": 4.931412894375857e-05,
      "loss": 4.8924,
      "step": 10
    },
    {
      "epoch": 0.0823045267489712,
      "grad_norm": 1.6995773315429688,
      "learning_rate": 4.862825788751715e-05,
      "loss": 3.8396,
      "step": 20
    },
    {
      "epoch": 0.12345679012345678,
      "grad_norm": 1.8235530853271484,
      "learning_rate": 4.794238683127572e-05,
      "loss": 3.6214,
      "step": 30
    },
    {
      "epoch": 0.1646090534979424,
      "grad_norm": 1.288438081741333,
      "learning_rate": 4.725651577503429e-05,
      "loss": 3.4163,
      "step": 40
    },
    {
      "epoch": 0.205761316872428,
      "grad_norm": 1.5939502716064453,
      "learning_rate": 4.657064471879287e-05,
      "loss": 3.2745,
      "step": 50
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 1.3326798677444458,
      "learning_rate": 4.5884773662551446e-05,
      "loss": 3.2004,
      "step": 60
    },
    {
      "epoch": 0.2880658436213992,
      "grad_norm": 1.2048859596252441,
      "learning_rate": 4.5198902606310016e-05,
      "loss": 3.1273,
      "step": 70
    },
    {
      "epoch": 0.3292181069958848,
      "grad_norm": 1.6720342636108398,
      "learning_rate": 4.451303155006859e-05,
      "loss": 2.9484,
      "step": 80
    },
    {
      "epoch": 0.37037037037037035,
      "grad_norm": 1.2196913957595825,
      "learning_rate": 4.3827160493827164e-05,
      "loss": 2.9477,
      "step": 90
    },
    {
      "epoch": 0.411522633744856,
      "grad_norm": 1.416808843612671,
      "learning_rate": 4.3141289437585735e-05,
      "loss": 2.9042,
      "step": 100
    },
    {
      "epoch": 0.45267489711934156,
      "grad_norm": 1.1883430480957031,
      "learning_rate": 4.2455418381344305e-05,
      "loss": 2.9056,
      "step": 110
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 1.4194164276123047,
      "learning_rate": 4.176954732510288e-05,
      "loss": 2.7841,
      "step": 120
    },
    {
      "epoch": 0.5349794238683128,
      "grad_norm": 1.431510329246521,
      "learning_rate": 4.108367626886145e-05,
      "loss": 2.8262,
      "step": 130
    },
    {
      "epoch": 0.5761316872427984,
      "grad_norm": 1.3164101839065552,
      "learning_rate": 4.039780521262003e-05,
      "loss": 2.8512,
      "step": 140
    },
    {
      "epoch": 0.6172839506172839,
      "grad_norm": 1.4199351072311401,
      "learning_rate": 3.971193415637861e-05,
      "loss": 2.7485,
      "step": 150
    },
    {
      "epoch": 0.6584362139917695,
      "grad_norm": 1.123904824256897,
      "learning_rate": 3.902606310013718e-05,
      "loss": 2.7493,
      "step": 160
    },
    {
      "epoch": 0.6995884773662552,
      "grad_norm": 1.19584321975708,
      "learning_rate": 3.834019204389575e-05,
      "loss": 2.8464,
      "step": 170
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 1.4791866540908813,
      "learning_rate": 3.7654320987654326e-05,
      "loss": 2.7099,
      "step": 180
    },
    {
      "epoch": 0.7818930041152263,
      "grad_norm": 1.362580418586731,
      "learning_rate": 3.6968449931412896e-05,
      "loss": 2.5292,
      "step": 190
    },
    {
      "epoch": 0.823045267489712,
      "grad_norm": 1.4087636470794678,
      "learning_rate": 3.628257887517147e-05,
      "loss": 2.6836,
      "step": 200
    },
    {
      "epoch": 0.8641975308641975,
      "grad_norm": 1.7240546941757202,
      "learning_rate": 3.5596707818930044e-05,
      "loss": 2.4909,
      "step": 210
    },
    {
      "epoch": 0.9053497942386831,
      "grad_norm": 1.7315484285354614,
      "learning_rate": 3.4910836762688615e-05,
      "loss": 2.6687,
      "step": 220
    },
    {
      "epoch": 0.9465020576131687,
      "grad_norm": 1.436145305633545,
      "learning_rate": 3.4224965706447185e-05,
      "loss": 2.5876,
      "step": 230
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 1.2281118631362915,
      "learning_rate": 3.353909465020576e-05,
      "loss": 2.6089,
      "step": 240
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.332926034927368,
      "eval_runtime": 6.1148,
      "eval_samples_per_second": 79.316,
      "eval_steps_per_second": 9.976,
      "step": 243
    },
    {
      "epoch": 1.02880658436214,
      "grad_norm": 1.2619045972824097,
      "learning_rate": 3.285322359396434e-05,
      "loss": 2.575,
      "step": 250
    },
    {
      "epoch": 1.0699588477366255,
      "grad_norm": 1.2277798652648926,
      "learning_rate": 3.216735253772291e-05,
      "loss": 2.4894,
      "step": 260
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 1.9896219968795776,
      "learning_rate": 3.148148148148148e-05,
      "loss": 2.5347,
      "step": 270
    },
    {
      "epoch": 1.1522633744855968,
      "grad_norm": 1.3315385580062866,
      "learning_rate": 3.079561042524006e-05,
      "loss": 2.4904,
      "step": 280
    },
    {
      "epoch": 1.1934156378600824,
      "grad_norm": 1.4838976860046387,
      "learning_rate": 3.010973936899863e-05,
      "loss": 2.4777,
      "step": 290
    },
    {
      "epoch": 1.2345679012345678,
      "grad_norm": 1.0804013013839722,
      "learning_rate": 2.9423868312757202e-05,
      "loss": 2.498,
      "step": 300
    },
    {
      "epoch": 1.2757201646090535,
      "grad_norm": 2.31587290763855,
      "learning_rate": 2.8737997256515776e-05,
      "loss": 2.5538,
      "step": 310
    },
    {
      "epoch": 1.316872427983539,
      "grad_norm": 1.4902608394622803,
      "learning_rate": 2.8052126200274347e-05,
      "loss": 2.5696,
      "step": 320
    },
    {
      "epoch": 1.3580246913580247,
      "grad_norm": 1.8600517511367798,
      "learning_rate": 2.736625514403292e-05,
      "loss": 2.5781,
      "step": 330
    },
    {
      "epoch": 1.3991769547325104,
      "grad_norm": 1.3305636644363403,
      "learning_rate": 2.6680384087791498e-05,
      "loss": 2.4579,
      "step": 340
    },
    {
      "epoch": 1.4403292181069958,
      "grad_norm": 1.2206007242202759,
      "learning_rate": 2.5994513031550072e-05,
      "loss": 2.6137,
      "step": 350
    },
    {
      "epoch": 1.4814814814814814,
      "grad_norm": 1.48521089553833,
      "learning_rate": 2.5308641975308646e-05,
      "loss": 2.4809,
      "step": 360
    },
    {
      "epoch": 1.522633744855967,
      "grad_norm": 1.6602150201797485,
      "learning_rate": 2.4622770919067216e-05,
      "loss": 2.5406,
      "step": 370
    },
    {
      "epoch": 1.5637860082304527,
      "grad_norm": 1.3677750825881958,
      "learning_rate": 2.393689986282579e-05,
      "loss": 2.5966,
      "step": 380
    },
    {
      "epoch": 1.6049382716049383,
      "grad_norm": 1.1313345432281494,
      "learning_rate": 2.3251028806584364e-05,
      "loss": 2.484,
      "step": 390
    },
    {
      "epoch": 1.646090534979424,
      "grad_norm": 1.4281612634658813,
      "learning_rate": 2.2565157750342935e-05,
      "loss": 2.6169,
      "step": 400
    },
    {
      "epoch": 1.6872427983539096,
      "grad_norm": 1.1831413507461548,
      "learning_rate": 2.1879286694101512e-05,
      "loss": 2.4235,
      "step": 410
    },
    {
      "epoch": 1.7283950617283952,
      "grad_norm": 3.303074598312378,
      "learning_rate": 2.1193415637860082e-05,
      "loss": 2.2667,
      "step": 420
    },
    {
      "epoch": 1.7695473251028808,
      "grad_norm": 1.3070828914642334,
      "learning_rate": 2.0507544581618656e-05,
      "loss": 2.3717,
      "step": 430
    },
    {
      "epoch": 1.8106995884773662,
      "grad_norm": 1.3104411363601685,
      "learning_rate": 1.982167352537723e-05,
      "loss": 2.5381,
      "step": 440
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 4.932701587677002,
      "learning_rate": 1.91358024691358e-05,
      "loss": 2.426,
      "step": 450
    },
    {
      "epoch": 1.8930041152263375,
      "grad_norm": 1.3115006685256958,
      "learning_rate": 1.8449931412894378e-05,
      "loss": 2.4663,
      "step": 460
    },
    {
      "epoch": 1.934156378600823,
      "grad_norm": 6.259378433227539,
      "learning_rate": 1.7764060356652952e-05,
      "loss": 2.3301,
      "step": 470
    },
    {
      "epoch": 1.9753086419753085,
      "grad_norm": 1.2007378339767456,
      "learning_rate": 1.7078189300411522e-05,
      "loss": 2.424,
      "step": 480
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.2166941165924072,
      "eval_runtime": 4.761,
      "eval_samples_per_second": 101.869,
      "eval_steps_per_second": 12.812,
      "step": 486
    }
  ],
  "logging_steps": 10,
  "max_steps": 729,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 525126189711360.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
